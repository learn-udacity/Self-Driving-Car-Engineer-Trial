<!-- udacimak v1.2.1 -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Hough Transform to Find Lane Lines</title>
  <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="../assets/css/plyr.css">
  <link rel="stylesheet" href="../assets/css/katex.min.css">
  <link rel="stylesheet" href="../assets/css/jquery.mCustomScrollbar.min.css">
  <link rel="stylesheet" href="../assets/css/styles.css">
  <link rel="shortcut icon" type="image/png" href="../assets/img/udacimak.png" />
</head>

<body>
  <div class="wrapper">
    <nav id="sidebar">
  <div class="sidebar-header">
    <h3>Computer Vision Fundamentals</h3>
  </div>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled components">
    <li class="">
      <a href="01. Power of Cameras.html">01. Power of Cameras</a>
    </li>
    <li class="">
      <a href="02. Setting up the Problem.html">02. Setting up the Problem</a>
    </li>
    <li class="">
      <a href="03. Color Selection.html">03. Color Selection</a>
    </li>
    <li class="">
      <a href="04. Color Selection Code Example.html">04. Color Selection Code Example</a>
    </li>
    <li class="">
      <a href="05. Color Selection.html">05. Color Selection</a>
    </li>
    <li class="">
      <a href="06. Region Masking.html">06. Region Masking</a>
    </li>
    <li class="">
      <a href="07. Color and Region Combined.html">07. Color and Region Combined</a>
    </li>
    <li class="">
      <a href="08. Color Region.html">08. Color Region</a>
    </li>
    <li class="">
      <a href="09. Finding Lines of Any Color.html">09. Finding Lines of Any Color</a>
    </li>
    <li class="">
      <a href="10. What is Computer Vision.html">10. What is Computer Vision?</a>
    </li>
    <li class="">
      <a href="11. Canny Edge Detection.html">11. Canny Edge Detection</a>
    </li>
    <li class="">
      <a href="12. Canny to Detect Lane Lines.html">12. Canny to Detect Lane Lines</a>
    </li>
    <li class="">
      <a href="13. Canny Edges.html">13. Canny Edges</a>
    </li>
    <li class="">
      <a href="14. Hough Transform.html">14. Hough Transform</a>
    </li>
    <li class="">
      <a href="15. Hough Transform to Find Lane Lines.html">15. Hough Transform to Find Lane Lines</a>
    </li>
    <li class="">
      <a href="16. Hough Transform.html">16. Hough Transform</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>
</nav>

    <div id="content">
      <header class="container-fluild header">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <div class="align-items-middle">
                <button type="button" id="sidebarCollapse" class="btn btn-toggle-sidebar">
                  <div></div>
                  <div></div>
                  <div></div>
                </button>

                <h1 style="display: inline-block">15. Hough Transform to Find Lane Lines</h1>
              </div>
            </div>
          </div>
        </div>
      </header>

      <main class="container">
        <div class="row">
          <div class="col-12">
            <div class="ud-atom">
  <h3><p>title</p></h3>
  <div>
  <h1 id="implementing-a-hough-transform-on-edge-detected-image">Implementing a Hough Transform on Edge Detected Image</h1>
<p>Now you know how the Hough Transform works, but to accomplish the task of finding lane lines, we need to specify some parameters to say what kind of lines we want to detect (i.e., long lines, short lines, bendy lines, dashed lines, etc.).  </p>
<p>To do this, we'll be using an OpenCV function called <code>HoughLinesP</code> that takes several parameters.  Let's code it up and find the lane lines in the image we detected edges in with the Canny function (for a look at coding up a Hough Transform from scratch, check <a href="https://alyssaq.github.io/2014/understanding-hough-transform/" target="_blank">this</a> out.) .</p>
<p>Here's the image we're working with:</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3><p>edges_exit</p></h3>
  <div>
  <figure class="figure">
    <img src="img/edges-exitramp.jpg" alt="" class="img img-fluid">
    <figcaption class="figure-caption">
      
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3><p>title</p></h3>
  <div>
  <p>Let's look at the input parameters for the OpenCV function <code>HoughLinesP</code> that we will use to find lines in the image.  You will call it like this:</p>
<pre><code class="python language-python">lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),
                                             min_line_length, max_line_gap)</code></pre>
<p>In this case, we are operating on the image <code>masked_edges</code> (the output from <code>Canny</code>) and the output from <code>HoughLinesP</code> will be <code>lines</code>, which will simply be an array containing the endpoints (x<sub>1</sub>, y<sub>1</sub>, x<sub>2</sub>, y<sub>2</sub>) of all line segments detected by the transform operation.  The other parameters define just what kind of line segments we're looking for.  </p>
<p>First off, <code>rho</code> and <code>theta</code> are the distance and angular resolution of our grid in Hough space.  Remember that, in Hough space, we have a grid laid out along the (Θ, ρ) axis.  You need to specify <code>rho</code> in units of pixels and <code>theta</code> in units of radians.  </p>
<p>So, what are reasonable values?  Well, rho takes a minimum value of 1,  and a reasonable starting place for theta is 1 degree (pi/180 in radians).  Scale these values up to be more flexible in your definition of what constitutes a line.</p>
<p>The <code>threshold</code> parameter specifies the minimum number of votes (intersections in a given grid cell) a candidate line needs to have to make it into the output.  The empty <code>np.array([])</code> is just a placeholder, no need to change it. <code>min_line_length</code> is the minimum length of a line (in pixels) that you will accept in the output, and <code>max_line_gap</code> is the maximum distance (again, in pixels) between segments that you will allow to be connected into a single line.  You can then iterate through your output <code>lines</code> and draw them onto the image to see what you got!</p>
<p>So, here's what its going to look like:</p>
<pre><code class="python language-python"># Do relevant imports
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import cv2

# Read in and grayscale the image
image = mpimg.imread('exit-ramp.jpg')
gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)

# Define a kernel size and apply Gaussian smoothing
kernel_size = 5
blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)

# Define our parameters for Canny and apply
low_threshold = 50
high_threshold = 150
masked_edges = cv2.Canny(blur_gray, low_threshold, high_threshold)

# Define the Hough transform parameters
# Make a blank the same size as our image to draw on
rho = 1
theta = np.pi/180
threshold = 1
min_line_length = 10
max_line_gap = 1
line_image = np.copy(image)*0 #creating a blank to draw lines on

# Run Hough on edge detected image
lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),
                            min_line_length, max_line_gap)

# Iterate over the output "lines" and draw lines on the blank
for line in lines:
    for x1,y1,x2,y2 in line:
        cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)

# Create a "color" binary image to combine with line image
color_edges = np.dstack((masked_edges, masked_edges, masked_edges)) 

# Draw the lines on the edge image
combo = cv2.addWeighted(color_edges, 0.8, line_image, 1, 0) 
plt.imshow(combo)</code></pre>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/hough-test.jpg" alt="" class="img img-fluid">
    <figcaption class="figure-caption">
      
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3><p>hough_text_outro</p></h3>
  <div>
  <p>As you can see I've detected lots of line segments!  Your job, in the next exercise, is to figure out which parameters do the best job of optimizing the detection of the lane lines.  Then, you'll want to apply a region of interest mask to filter out detected line segments in other areas of the image.  Earlier in this lesson you used a triangular region mask, but this time you'll get a chance to use a quadrilateral region mask using the <code>cv2.fillPoly()</code> function (keep in mind though, you could use this same method to mask an arbitrarily complex polygon region).   When you're finished you'll be ready to apply the skills you've learned to do the project at the end of this lesson.  </p>
</div>

</div>
<div class="divider"></div>
          </div>
        </div>
      </main>

      <footer class="footer">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <p class="text-center">
                <a href="https://github.com/udacimak/udacimak#readme" target="_blank">udacimak v1.2.1</a>
              </p>
            </div>
          </div>
        </div>
      </footer>
    </div>
  </div>


  <script src="../assets/js/jquery-3.3.1.min.js"></script>
  <script src="../assets/js/plyr.polyfilled.min.js"></script>
  <script src="../assets/js/bootstrap.min.js"></script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js"></script>
  <script src="../assets/js/katex.min.js"></script>
  <script>
    // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });
    });
  </script>
</body>

</html>
